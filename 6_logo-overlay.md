# Paso 6 â€” Logo Overlay

**Problema:** Sergio menciona empresas, productos y marcas en sus videos. Quiere que aparezca el logo en pantalla cuando los nombra. Hacerlo manualmente en DaVinci toma mucho tiempo.

**SoluciÃ³n:** Semi-automatizado. Leer la transcripciÃ³n (Paso 5) â†’ detectar marcas â†’ generar `overlay-logos.md` â†’ Sergio valida con âœ…/âŒ â†’ aplicar overlays con ffmpeg en single pass.

**Prerequisito:** Paso 5 completado (`fuente/transcription/transcription_original.json` debe existir).

---

## Flujo completo

### 1. ğŸŒ‘ Sinistra detecta marcas en la transcripciÃ³n

Lee `transcription_original.json` (generado en Paso 5), busca menciones de marcas tech en las palabras con timestamps, y genera `fuente/transcription/overlay-logos.md`.

**NO vuelve a llamar a Whisper API.** La transcripciÃ³n ya existe.

**Proceso de traducciÃ³n (lo hace Sinistra manualmente, no un script):**

1. Abre `fuente/transcription/transcription_original.json`
2. Recorre el array `words[]` buscando nombres de marcas tech (OpenAI, Anthropic, Google, Claude, etc.)
3. Por cada marca encontrada, toma el `start` de esa palabra como timestamp exacto
4. Genera una entrada en `overlay-logos.md` con formato:
   ```
   [MM:SS - MM:SS] "contexto de la frase donde aparece la marca"
     â†’ nombre-logo.png | âœ…
   ```
   Donde el primer timestamp = `word.start` y el segundo = `word.start + 3s` (duraciÃ³n del logo)
5. Marca todas como âœ… por defecto â€” Sergio decide cuÃ¡les quitar

**Ejemplo concreto de la traducciÃ³n:**

JSON (input):
```json
{ "word": "OpenAI", "start": 5.10, "end": 5.58 }
```

overlay-logos.md (output):
```
[0:05 - 0:08] "algo aÃºn mÃ¡s fuerte OpenAI los creadores de ChatGPT"
  â†’ openai.png | âœ…
```

**Â¿Por quÃ© no es un script?** Porque la detecciÃ³n de marcas requiere criterio: "Apple" puede ser la empresa o la fruta, "Meta" puede ser la empresa o la palabra "meta". Sinistra usa contexto de la frase para decidir. Un script regex tendrÃ­a muchos falsos positivos.

### 2. ğŸŒ‘ Sinistra descarga logos

Los logos se buscan en este orden:

1. **SVGL API** (automÃ¡tico, +500 logos tech con variantes light/dark)
2. **Repo local** (`~/Documents/Edicion/Serudda/recursos/logos/`)
3. **Sergio lo agrega manualmente**

Los logos descargados se guardan en `fuente/logos/` dentro del folder del video.

```bash
# Buscar en SVGL
curl -sS "https://api.svgl.app?search=anthropic"

# Descargar SVG y convertir a PNG 256x256
curl -sS "https://svgl.app/library/anthropic_white.svg" -o fuente/logos/anthropic.svg
rsvg-convert -w 256 -h 256 --keep-aspect-ratio fuente/logos/anthropic.svg -o fuente/logos/anthropic.png
```

### 3. ğŸ¬ Sergio revisa `fuente/transcription/overlay-logos.md`

Solo cambia âœ… â†” âŒ. Nada mÃ¡s.

```
[5:10 - 5:13] "algo aÃºn mÃ¡s fuerte OpenAI los creadores de ChatGPT"
  â†’ openai.png | âœ…

[5:12 - 5:15] "OpenAI los creadores de ChatGPT confirmaron en su documentaciÃ³n"
  â†’ chatgpt.png | âŒ
```

**Tips para la revisiÃ³n:**

- Si una marca se menciona varias veces seguidas (ej: OpenAI 3 veces en 20 segundos), dejar solo la primera âœ… y las demÃ¡s âŒ
- Si el intro se repite (teleprompter), dejar solo una menciÃ³n âœ…
- 3 segundos por logo es el default â€” suficiente para que se vea sin molestar

### 4. ğŸ¬ Sergio corre el script

```bash
# Ver quÃ© va a hacer (sin generar video)
python3 scripts/logo-overlay.py $VIDEO --dry-run

# Solo ver el comando ffmpeg que generarÃ­a
python3 scripts/logo-overlay.py $VIDEO --print-cmd

# Generar el video (tarda ~10-20 min para 17 min de video)
python3 scripts/logo-overlay.py $VIDEO

# Personalizar
python3 scripts/logo-overlay.py $VIDEO --size 150 --padding 50
```

| Flag | Default | QuÃ© hace |
|------|---------|----------|
| `--video` | 4_video_jumpcut.mp4 | Video de entrada |
| `--output` | `<video>_logos.mp4` | Video de salida (en output/) |
| `--size` | 120 | TamaÃ±o del logo en px |
| `--padding` | 40 | Padding del borde en px |
| `--fade` | 0.3 | Fade in/out en segundos |
| `--duration` | 3 | DuraciÃ³n del logo en pantalla (segundos) |
| `--crf` | 18 | Calidad de video |
| `--dry-run` | â€” | Solo muestra detecciones |
| `--print-cmd` | â€” | Solo imprime el comando ffmpeg |

---

## Archivos involucrados

```
fuente/
â”œâ”€â”€ transcription/
â”‚   â”œâ”€â”€ transcription_original.json   â† INPUT (del Paso 5, NO tocar)
â”‚   â””â”€â”€ overlay-logos.md              â† Detecciones para revisiÃ³n (âœ…/âŒ)
â”œâ”€â”€ logos/                            â† PNGs descargados
â”‚   â”œâ”€â”€ anthropic.png
â”‚   â”œâ”€â”€ openai.png
â”‚   â””â”€â”€ ...
â””â”€â”€ video/
    â””â”€â”€ 4_video_jumpcut.mp4           â† Video de entrada

output/
â””â”€â”€ 4_video_jumpcut_logos.mp4         â† Video con logos
```

---

## CÃ³mo funciona el script internamente

### Single pass (no batches)

El script genera UN SOLO comando ffmpeg con todos los overlays en el `filter_complex`. Cada logo es un input separado y se activa/desactiva con `enable='between(t,start,end)'`.

**Â¿Por quÃ© single pass?** Probamos batches (dividir en mÃºltiples passes) y los logos no aparecÃ­an en el video final. Single pass funciona correctamente.

### Parseo de `overlay-logos.md`

El script busca lÃ­neas con este formato:

```
[MM:SS - MM:SS] "cualquier texto"
  â†’ nombre_logo.png | âœ…
```

- Solo procesa las marcadas con âœ…
- Detecta overlaps y apila logos verticalmente
- El nombre del logo debe coincidir con el archivo en `fuente/logos/`

### Overlays con ffmpeg

Cada logo se aplica con:

- `scale` â†’ redimensiona al tamaÃ±o configurado
- `format=rgba` â†’ preserva transparencia del PNG
- `fade` â†’ fade in al inicio, fade out al final
- `overlay` con `enable='between(t,start,end)'` â†’ solo visible en el rango
- PosiciÃ³n: esquina inferior derecha con padding
- Logos solapados en tiempo se apilan verticalmente

---

## ResoluciÃ³n de Logos (orden de prioridad)

1. **SVGL API** â€” `curl -sS "https://api.svgl.app?search=nombre"`
2. **Repo local** â€” `~/Documents/Edicion/Serudda/recursos/logos/` (~120 marcas en slug)
3. **Manual** â€” Sergio lo busca y lo deja en `fuente/logos/`

---

## Lecciones aprendidas

1. **Timestamps por segmento son imprecisos.** Siempre usar word-level (Paso 5 ya lo hace).
2. **Batches no funcionan.** Single pass es la soluciÃ³n.
3. **3 segundos es la duraciÃ³n ideal.** 5s es demasiado largo.
4. **El logo aparece cuando se dice la palabra, no antes.**

---

## ğŸ› Bug abierto: Logos no aparecen en video completo (Feb 19, 2026)

### SÃ­ntoma
El script genera el video (re-encodea completo, ~7 min, ~766MB) pero los logos NO aparecen visualmente en ningÃºn timestamp. ffmpeg reporta stream mapping correcto con todos los overlays.

### Lo que SÃ funciona
- **Clip corto (10s) con 1 logo** â†’ logo visible âœ…
- **Video completo con 1 logo, comando manual single-line** â†’ logo visible âœ…
  ```bash
  ffmpeg -i video.mp4 -i logo.png -filter_complex "[1:v]scale=...;[0:v][logo]overlay=...:enable='between(t,105,108)'[out]" -map "[out]" -map 0:a -c:v libx264 -crf 18 -preset fast -c:a copy -y output.mp4
  ```

### Lo que NO funciona
- **Video completo con 12 logos via `logo-overlay.py`** â†’ logos no aparecen âŒ
- Tanto con `subprocess.run(cmd_list)` como generando `.sh` + `bash script.sh`
- Tanto con `enable='between(t,105,108)'` (comillas simples) como `enable=between(t\,105\,108)` (commas escapadas)

### HipÃ³tesis descartadas
- âŒ Timestamps incorrectos â€” transcripciÃ³n coincide con duraciÃ³n del video (1030s ambos)
- âŒ PTS del video descalibrado â€” `start_time: 0.021` (normal)
- âŒ `-ss` reseteando timestamps â€” no se usa `-ss` en el script
- âŒ Logos PNG corruptos â€” funcionan en test de clip corto
- âŒ `\n` en filter_complex â€” eliminado, mismo resultado
- âŒ `capture_output=True` ocultando errores â€” removido, mismo resultado

### HipÃ³tesis pendientes de investigar
- **Â¿El encadenamiento de 12 overlays causa el problema?** El test de 1 logo manual funciona. Nunca se probÃ³ correctamente un comando manual con 2+ logos en video completo (los intentos previos se pegaron multi-lÃ­nea desde Telegram y podrÃ­an haberse corrompido).
- **Â¿Algo en el `.sh` generado vs el comando manual difiere sutilmente?** El `.sh` generado se ve idÃ©ntico al formato manual, pero no se ha probado corriendo el `.sh` manualmente con `bash`.
- **Â¿El video `4_video_jumpcut.mp4` tiene algo especial?** Fue creado concatenando 160 segmentos .ts. Los timestamps podrÃ­an tener discontinuidades internas que confunden el `enable=between()` en overlays encadenados.
- **Â¿Probar con `drawtext` como debug?** Poner un texto con timestamp visible en el video para confirmar quÃ© valores tiene `t` en cada momento.

### PrÃ³ximo paso sugerido
1. Probar corriendo `bash tmp/logo_overlay_cmd.sh` directamente en terminal (no via Python)
2. Si no funciona, probar con solo 2 logos (no 12) en un `.sh` manual
3. Si 2 logos no funcionan, probar `drawtext=text='%{pts}':fontsize=48` para ver timestamps reales del video

---

## Dependencias

- `ffmpeg` â€” overlays de video
- `rsvg-convert` â€” conversiÃ³n SVG â†’ PNG (`brew install librsvg`)
- `python3` â€” script de overlay
